# Cultural Harms In GAI
In this project, we look at the impact of Generative Artificial Intelligence (GAI) models, specifically text-to-image generators (T2Is), on the representation of non-Western cultures, with a focus on Indian contexts. Despite the transformative potential of T2Is in content creation, concerns have arisen regarding biases that may lead to misrepresentations and marginalizations. Through a community-centered approach and grounded theory analysis of 5 focus groups from diverse Indian subcultures, we explore how GAI outputs to English prompts depict Indian culture and its subcultures, uncovering novel representational harms such as exoticism and cultural misappropriation. 

The repository consists of the following data:
1. All the image generated during the focus group.
2. All the prompts provided by the participants.
3. The anonymized participant list and their respective focus group association.
4. Surveys and additional material used to collect information during the focus group.
5. Quotes related to harms identified and thematically categorized.
6. Codebook of the focus group with the most common discussion points encountered.


# Project Contact Information


Faculty Advisor:

Name: Dr. Aylin Caliskan //
Email: aylin@uw.edu
Affiliation: University of Washington

Name: Dr. Shomir Wilson
Email: shomir@psu.edu
Affiliation: Pennsylvania State University


PhD Researchers:

Name: Pranav Narayanan Venkit
Email: pranav.venkit@psu.edu
Affiliation: Pennsylvania State University

Name: Sourojit Ghosh
Email: ghosh100@uw.edu
Affiliation: University of Washington

Name: Sanjana Gautam
Email: sanjana.gautam@psu.edu
Affiliation: Pennsylvania State University


Acknowledgement:
This work was supported by the U.S. National Institute of Standards and Technology (NIST) Grant 60NANB23D194.
Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect those of NIST.
